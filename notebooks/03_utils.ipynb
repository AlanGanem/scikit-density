{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import copy\n",
    "#linalg\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import scipy\n",
    "\n",
    "try:\n",
    "    from sparse_dot_topn import awesome_cossim_topn\n",
    "except ImportError as e:\n",
    "    warn(f\"{e}\")\n",
    "    warn(\"sparse_dot_topn module not installed, will use naive dot product for vector query. This may lead to memory overload\")\n",
    "\n",
    "# data and viz\n",
    "from sklearn.datasets import make_regression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helping Functions - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#auxiliary functions\n",
    "def ctqdm(iterable, verbose = False, notebook = False,**tqdm_kwargs):\n",
    "    '''\n",
    "    progress bar handler (custom tqdm)\n",
    "    '''\n",
    "    if not verbose:\n",
    "        return iterable\n",
    "    else:\n",
    "        if notebook:\n",
    "            return tqdm.notebook.tqdm(iterable,**tqdm_kwargs)\n",
    "        else:\n",
    "            return tqdm.tqdm(iterable,**tqdm_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#shape fixing functions\n",
    "def _add_n_dists_axis(X):\n",
    "    '''\n",
    "    when the array represents a single dist of shape (n_samples, n_dims),\n",
    "    returns a 3 axis representation (1[n_dists], n_samples, n_dims)\n",
    "    '''\n",
    "    _assert_dim_2d(X)\n",
    "    return X.reshape(1,*X.shape)\n",
    "\n",
    "def _add_n_samples_axis(X):\n",
    "    '''\n",
    "    when the array represents a single sample dists of shape (n_dists, n_dims),\n",
    "    returns a 3 axis representation (n_dists, 1[n_samples], n_dims)\n",
    "    '''\n",
    "    _assert_dim_2d(X)\n",
    "    return X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\n",
    "def _add_n_dims_axis(X):\n",
    "    '''\n",
    "    when the array represents a single dim of shape (n_dists ,n_samples,),\n",
    "    returns a 3 axis representation (n_dists, n_samples, 1[n_dims])\n",
    "    '''\n",
    "    _assert_dim_2d(X)\n",
    "    return X.reshape(1, *X.shape)\n",
    "\n",
    "\n",
    "# some alises of above functions may be lsited below\n",
    "def _fix_one_sample_2d(X):\n",
    "    '''\n",
    "    returns a 3d array of shape (n_samples, 1, n_dims)\n",
    "    given an array of shape (n_samples, n_dims)\n",
    "    '''\n",
    "    try: return _assert_dim_3d(X)\n",
    "    except: return X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\n",
    "def _fix_one_dist_2d(X):\n",
    "    '''\n",
    "    returns a one distributiton 3d array of shape (1,n_sample_per_distribution,n_dims)\n",
    "    given an array of shape (n_sample_per_distribution,n_dims)\n",
    "    '''\n",
    "    try: return _assert_dim_3d(X)\n",
    "    except: return X.reshape(1, X.shape[0], X.shape[1])\n",
    "\n",
    "def _fix_dist_1d(X):\n",
    "    '''\n",
    "    returns a one dimension dist 3d array of shape (n_distributions, n_sample_per_distribution, 1)\n",
    "    given an array of shape (n_distributions, n_sample_per_distribution)\n",
    "    '''\n",
    "    try: return _assert_dim_3d(X)\n",
    "    except: return X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "def _fix_one_dist_1d(X):\n",
    "    ''' \n",
    "    returns a one dimension dist 3d array of shape (1, n_sample_per_distribution, 1)\n",
    "    given an array of shape (n_sample_per_distribution,)\n",
    "    '''\n",
    "    try: return _assert_dim_3d(X)\n",
    "    except: return X.reshape(1, X.shape[0], 1)\n",
    "\n",
    "def _fix_X_1d(X):\n",
    "    '''Makes 1d array a 2d one'''\n",
    "    #X = np.array(X)\n",
    "    #reshape if shape == (n_samples,)\n",
    "    X = X if len(X.shape) > 1 else X.reshape(-1,1)\n",
    "    return X\n",
    "\n",
    "def _assert_dim_3d(X):\n",
    "    '''\n",
    "    usefull for distribution arrays of shape (n_distributions, n_sample_per_distribution, n_dims_in_distribtuion)\n",
    "    '''\n",
    "    assert len(X.shape) == 3, f'X must have 3 dimensions: (n_distributions, n_sample_per_distribution, n_dims_in_distribtuion). got {X.shape} insted'\n",
    "    return X\n",
    "\n",
    "def _assert_dim_2d(X):\n",
    "    '''\n",
    "    assert ana rray have 2 dim\n",
    "    '''\n",
    "    assert len(X.shape) == 2, f'X must have 2 dimensions. got {X.shape} instead'\n",
    "    return X\n",
    "\n",
    "def _assert_dim_1d(X):\n",
    "    '''\n",
    "    assert array has 1dim\n",
    "    '''\n",
    "    assert len(X.shape) == 1, f'X must have 1 dimension. got {X.shape} instead'\n",
    "    return X\n",
    "\n",
    "def pad_to_shape(array, shape):\n",
    "    '''fill array with trilling zeros to match shape'''\n",
    "    arr = np.zeros(shape)    \n",
    "    arr[tuple(slice(0,i) for i in array.shape)] = array\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sample_idxs(weights, sample_size, replace = True):\n",
    "    '''\n",
    "    sample indexes based on weights array\n",
    "    weights array should have shape (n_dists, n_draw_values)\n",
    "    '''\n",
    "    #make sure weights sum up to 1\n",
    "    weights = normalize(weights, norm = 'l1', axis = 1)\n",
    "    sampled_idxs = [np.random.choice([*range(w.shape[0])], size = sample_size, p = w, replace = replace) for w in weights]\n",
    "    return np.array(sampled_idxs)\n",
    "    \n",
    "\n",
    "def sample_multi_dim(arr, sample_size, weights, replace = True, axis = 0):\n",
    "    '''\n",
    "    function that extends np.random.choice to work with arbitrary axis sampling\n",
    "    len(weight) must be equal to n elements in axis\n",
    "    '''    \n",
    "    if not weights is None:\n",
    "        assert _assert_dim_1d(weights).shape[0] == arr.shape[axis], f'cannot allign weights and arr along axis {axis}'\n",
    "    sampled_idxs = np.random.choice([*range(arr.shape[axis])], size = sample_size, p = weights, replace = replace)\n",
    "    return np.take(arr, sampled_idxs, axis=axis)\n",
    "\n",
    "def sample_from_dist_array(arr, sample_size, weights = None, replace = True):\n",
    "    '''\n",
    "    samples from array along axis\n",
    "    array should be of shape (n_dists, n_sampels, n_dims)\n",
    "    '''\n",
    "    arr = _fix_dist_1d(arr)\n",
    "    #handle wieghts shape and handles None case\n",
    "    if not weights is None:\n",
    "        assert weights.shape == arr.shape[:-1], f'weights not allignable with arr: {weights.shape} and {arr.shape[:-1]}'\n",
    "        #normalize probas\n",
    "        weights = weights/weights.sum(axis = -1).reshape(-1,1)\n",
    "    else:\n",
    "        weights = [None for _ in range(arr.shape[0])]\n",
    "        \n",
    "    samples = [(sample_multi_dim(arr[i], sample_size, weights[i], replace = replace, axis = 0)) for i in range(arr.shape[0])]\n",
    "    return np.array(samples)\n",
    "\n",
    "def add_noise(x, std = 1e-6):\n",
    "    '''\n",
    "    adds small white noise to array\n",
    "    '''\n",
    "    return x + np.random.normal(scale = std, size = x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing `sample_from_dist_array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 10, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.random.randn(300,150,5)\n",
    "weights = np.abs(np.random.randn(300,150))\n",
    "sample_from_dist_array(arr, 10, weights = weights, replace = True).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testin `add_noise`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.86201047e-07, -2.94832334e-07,  1.10836104e-06,  9.22854428e-08,\n",
       "        6.09320589e-07,  1.49150601e-06, -6.96548937e-07, -2.72424513e-07,\n",
       "        1.49209658e-07,  9.85568069e-07])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_noise(np.zeros(10),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse array functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sparse_mul_col(arr, vector):\n",
    "    '''multiplies matrix columns by vector'''\n",
    "    m = scipy.sparse.csc_matrix(arr)\n",
    "    m.data = m.data*np.take(vector, m.indices)         \n",
    "    return m\n",
    "\n",
    "def sparse_mul_row(arr, vector):\n",
    "    '''multiplies matrix rows by vector'''\n",
    "    m = scipy.sparse.csr_matrix(arr)\n",
    "    m.data = m.data*np.take(vector, m.indices)         \n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighbor functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#cossim query functions\n",
    "\n",
    "def transform_similarity_weights(query_vector, query_space, beta = 1, gamma = 1):\n",
    "    '''\n",
    "    handles query vector and query space using stretch factors beta and gamma \n",
    "    '''\n",
    "    if not scipy.sparse.issparse(query_vector):\n",
    "        query_vector = scipy.sparse.csr_matrix(query_vector)\n",
    "    \n",
    "    if not scipy.sparse.issparse(query_space):\n",
    "        space = scipy.sparse.csr_matrix(query_space)\n",
    "    \n",
    "    if gamma == 1:\n",
    "        query_space = normalize(query_space)\n",
    "    elif gamma == 0:\n",
    "        query_space.data = query_space.data**gamma\n",
    "        query_space = normalize(query_space)\n",
    "    else:\n",
    "        #normalize, apply beta and normalize again\n",
    "        query_space = normalize(query_space)\n",
    "        query_space.data = query_space.data**gamma\n",
    "        query_space = normalize(query_space)\n",
    "    \n",
    "    if beta == 1:\n",
    "        query_vector = normalize(query_vector)\n",
    "    elif beta == 0:\n",
    "        query_vector.data = query_vector.data**beta\n",
    "        query_vector = normalize(query_vector)\n",
    "    else:\n",
    "        #normalize, apply gamma and normalize again\n",
    "        query_vector = normalize(query_vector)\n",
    "        query_vector.data = query_vector.data**beta\n",
    "        query_vector = normalize(query_vector)\n",
    "    \n",
    "    return query_vector, query_space\n",
    "\n",
    "def sparse_dot_product(A, B, ntop, lower_bound):\n",
    "    '''dot product of two saprse matrices'''\n",
    "    return awesome_cossim_topn(A, B,ntop=ntop, lower_bound=lower_bound)\n",
    "\n",
    "def cos_sim_query(query_vector, query_space, n_neighbors=50, lower_bound=0.0, beta = 1, gamma = 1):\n",
    "    '''make cos similarity query of query_vector on query_space\n",
    "    beta is a weightening factor such that query_space = normalize(query_space^beta)\n",
    "    beta greater than one ensure higher magnitude components recieves more importance when querying\n",
    "    returns idx, sim\n",
    "    '''\n",
    "    \n",
    "    query_vector, query_space = copy.deepcopy(query_vector), copy.deepcopy(query_space)\n",
    "    query_vector, query_space = transform_similarity_weights(query_vector, query_space, beta, gamma)\n",
    "        \n",
    "    try:\n",
    "        sim_matrix = (awesome_cossim_topn(query_vector, query_space.T,\n",
    "                                         ntop=n_neighbors, lower_bound=lower_bound))\n",
    "        \n",
    "        sim_matrix = scipy.sparse.coo_matrix(sim_matrix)\n",
    "    \n",
    "        idx = []\n",
    "        sim = []\n",
    "        arr_sizes = []\n",
    "        for row in range(sim_matrix.shape[0]):\n",
    "            s = sim_matrix.data[sim_matrix.row == row]\n",
    "            i = sim_matrix.col[sim_matrix.row == row]\n",
    "            sim.append(s)\n",
    "            idx.append(i)\n",
    "            arr_sizes.append(len(s))\n",
    "\n",
    "        max_size = max(arr_sizes)\n",
    "        idx = np.array([pad_to_shape(i, max_size) for i in idx]).astype(int)\n",
    "        sim = np.array([pad_to_shape(s, max_size) for i in sim])\n",
    "        if idx.shape[1] == 0:\n",
    "            raise ValueError('No similarity greater than lower_bound found. Choose a lower threshold.')\n",
    "        return  idx, sim\n",
    "    \n",
    "    except NameError: #in case sparse_dot_topn is not instaled\n",
    "        dist, idx = (\n",
    "            NearestNeighbors(n_neighbors = n_neighbors, radius = 1 - lower_bound, metric = 'cosine', n_jobs = -1)\n",
    "            .fit(query_space)\n",
    "            .kneighbors(query_vector)\n",
    "        )\n",
    "        return idx, 1 - dist # <- cos_sim = 1 - cos_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(x))\n",
    "\n",
    "def make_bimodal_regression(n_samples, split_frac = 0.8, bimodal_inbalance = 0, random_state = None):\n",
    "    '''make 2d bimodal regression dataset\n",
    "    returns X_train, y_train, X_test, y_test \n",
    "    '''\n",
    "    \n",
    "    X,y = make_regression(\n",
    "        n_samples=10000,\n",
    "        n_features=15,\n",
    "        n_informative=6,\n",
    "        n_targets=2,\n",
    "        bias=500,\n",
    "        effective_rank=None,\n",
    "        tail_strength=2,\n",
    "        noise=0.2,\n",
    "        shuffle=True,\n",
    "        coef=False,\n",
    "        random_state = random_state\n",
    "    )\n",
    "\n",
    "\n",
    "    #make one of X[1] feature mode weightening    \n",
    "    bimodal_factors = (sigmoid(bimodal_inbalance*X[:,-1]) > np.random.random(size = X.shape[0])).astype(int)\n",
    "    bimodal_factors[bimodal_factors == 0] = -1\n",
    "    bimodal_factors = bimodal_factors.reshape(-1,1)\n",
    "\n",
    "    y = bimodal_factors*y\n",
    "    X_train, X_test = X[:int(split_frac*len(X))], X[int(split_frac*len(X)):]\n",
    "    y_train, y_test = y[:int(split_frac*len(X))], y[int(split_frac*len(X)):]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data viz functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_distplot(sample,true_value,y_test,):\n",
    "    \n",
    "    if (len(sample.shape) > 1) and (sample.shape[-1] == 2):\n",
    "        jntplot = sns.jointplot(sample[:,0], sample[:,1], joint_kws = {'label':'Model Samples', 'alpha':1})\n",
    "        jntplot.ax_joint.scatter(y_test[:,0], y_test[:,1], color = 'orange', alpha = 0.01, label = 'Target Distribution')\n",
    "        jntplot.ax_joint.scatter(true_value[0], true_value[1], color = 'red', label = 'Target Value')                \n",
    "        jntplot.ax_joint.legend()\n",
    "\n",
    "    else:\n",
    "        sns.distplot(sample, kde = True, bins = 20, hist_kws = {'label':'Model Samples'})\n",
    "        dst = sns.distplot(y_test, kde = True, bins = 20, hist_kws = {'label':'Target Distribution'})\n",
    "        dst._axes.axvline(true_value[0], color = 'r')\n",
    "        dst._axes.legend()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helping Classes - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DelegateEstimatorMixIn(object):\n",
    "    '''\n",
    "    class to make getattr method look for method in estimator object if not found in parent class.\n",
    "    parent class should contain 'estimator' attribute\n",
    "    '''\n",
    "    estimator = None\n",
    "    def __getattr__(self,attr):\n",
    "        # if use try except, gets infinite recursion\n",
    "        \n",
    "        if (attr in dir(self)) or (attr in list(self.__dict__)):\n",
    "            return object.__getattribute__(self, attr)\n",
    "        elif (attr in dir(self.estimator)) or (attr in list(self.estimator.__dict__)) and (not self.estimator):\n",
    "            return object.__getattribute__(self.estimator, attr)        \n",
    "        else: \n",
    "            return object.__getattribute__(self, attr) #raise key error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_ensemble.ipynb.\n",
      "Converted 02_core.random_variable.ipynb.\n",
      "Converted 03_utils.ipynb.\n",
      "Converted 04_metrics.ipynb.\n",
      "Converted 05_neighbors.ipynb.\n",
      "Converted 06_kde_baesyan_nets.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
