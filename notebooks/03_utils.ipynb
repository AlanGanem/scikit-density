{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import scipy\n",
    "\n",
    "\n",
    "try:\n",
    "    from sparse_dot_topn import awesome_cossim_topn\n",
    "except ImportError as e:\n",
    "    warn(f\"{e}\")\n",
    "    warn(\"sparse_dot_topn module not installed, will use naive dot product for vector query. This may lead to memory overload\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helping Functions - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#auxiliary functions\n",
    "def ctqdm(iterable, verbose = False, notebook = False,**tqdm_kwargs):\n",
    "    '''\n",
    "    progress bar handler (custom tqdm)\n",
    "    '''\n",
    "    if not verbose:\n",
    "        return iterable\n",
    "    else:\n",
    "        if notebook:\n",
    "            return tqdm.notebook.tqdm(iterable,**tqdm_kwargs)\n",
    "        else:\n",
    "            return tqdm.tqdm(iterable,**tqdm_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#shape fixing functions\n",
    "\n",
    "def _fix_one_sample_2d(X):\n",
    "    '''\n",
    "    returns a 3d array of shape (n_samples, 1, n_dims)\n",
    "    given an array of shape (n_samples, n_dims)\n",
    "    '''\n",
    "    try: return _assert_dim_3d(X)\n",
    "    except: return X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\n",
    "def _fix_one_dist_2d(X):\n",
    "    '''\n",
    "    returns a one distributiton 3d array of shape (1,n_sample_per_distribution,n_dims)\n",
    "    given an array of shape (n_sample_per_distribution,n_dims)\n",
    "    '''\n",
    "    try: return _assert_dim_3d(X)\n",
    "    except: return X.reshape(1, X.shape[0], X.shape[1])\n",
    "\n",
    "def _fix_dist_1d(X):\n",
    "    '''\n",
    "    returns a one dimension dist 3d array of shape (n_distributions, n_sample_per_distribution, 1)\n",
    "    given an array of shape (n_distributions, n_sample_per_distribution)\n",
    "    '''\n",
    "    try: return _assert_dim_3d(X)\n",
    "    except: return X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "def _fix_one_dist_1d(X):\n",
    "    ''' \n",
    "    returns a one dimension dist 3d array of shape (1, n_sample_per_distribution, 1)\n",
    "    given an array of shape (n_sample_per_distribution,)\n",
    "    '''\n",
    "    try: return _assert_dim_3d(X)\n",
    "    except: return X.reshape(1, X.shape[0], 1)\n",
    "\n",
    "def _fix_X_1d(X):\n",
    "    '''Makes 1d array a 2d one'''\n",
    "    #X = np.array(X)\n",
    "    #reshape if shape == (n_samples,)\n",
    "    X = X if len(X.shape) > 1 else X.reshape(-1,1)\n",
    "    return X\n",
    "\n",
    "def _assert_dim_3d(X):\n",
    "    '''\n",
    "    usefull for distribution arrays of shape (n_distributions, n_sample_per_distribution, n_dims_in_distribtuion)\n",
    "    '''\n",
    "    assert len(X.shape) == 3, 'X must have 3 dimensions: (n_distributions, n_sample_per_distribution, n_dims_in_distribtuion)'\n",
    "    return X\n",
    "\n",
    "def pad_to_shape(array, shape):\n",
    "    '''fill array with trilling zeros to match shape'''\n",
    "    arr = np.zeros(shape)    \n",
    "    arr[tuple(slice(0,i) for i in array.shape)] = array\n",
    "    return arr\n",
    "\n",
    "def sample_multi_dim(arr, size, weights, replace = True, axis = 0):\n",
    "    '''\n",
    "    function that extends np.random.choice to work with arbitrary axis sampling\n",
    "    len(weight) must be equal to n elements in axis\n",
    "    '''\n",
    "    assert len(weights) == arr.shape[axis]\n",
    "    sampled_idxs = np.random.choice([*range(arr.shape[axis])], size = size, p = weights, replace = replace)\n",
    "    return np.take(arr, sampled_idxs, axis=axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#cossim query functions\n",
    "\n",
    "def transform_similarity_weights(query_vector, query_space, beta = 1, gamma = 1):\n",
    "    \n",
    "    if not scipy.sparse.issparse(query_vector):\n",
    "        query_vector = scipy.sparse.csr_matrix(query_vector)\n",
    "    \n",
    "    if not scipy.sparse.issparse(query_space):\n",
    "        space = scipy.sparse.csr_matrix(query_space)\n",
    "    \n",
    "    if gamma == 1:\n",
    "        query_space = normalize(query_space)\n",
    "    elif gamma == 0:\n",
    "        query_space.data = query_space.data**gamma\n",
    "        query_space = normalize(query_space)\n",
    "    else:\n",
    "        #normalize, apply beta and normalize again\n",
    "        query_space = normalize(query_space)\n",
    "        query_space.data = query_space.data**gamma\n",
    "        query_space = normalize(query_space)\n",
    "    \n",
    "    if beta == 1:\n",
    "        query_vector = normalize(query_vector)\n",
    "    elif beta == 0:\n",
    "        query_vector.data = query_vector.data**beta\n",
    "        query_vector = normalize(query_vector)\n",
    "    else:\n",
    "        #normalize, apply gamma and normalize again\n",
    "        query_vector = normalize(query_vector)\n",
    "        query_vector.data = query_vector.data**beta\n",
    "        query_vector = normalize(query_vector)\n",
    "    \n",
    "    return query_vector, query_space\n",
    "\n",
    "def cos_sim_query(query_vector, query_space, n_neighbors=50, lower_bound=0.0, beta = 1, gamma = 1):\n",
    "    '''make cos similarity query of query_vector on query_space\n",
    "    beta is a weightening factor such that query_space = normalize(query_space^beta)\n",
    "    beta greater than one ensure higher magnitude components recieves more importance when querying\n",
    "    '''\n",
    "    \n",
    "    query_vector, query_space = copy.deepcopy(query_vector), copy.deepcopy(query_space)\n",
    "    query_vector, query_space = transform_similarity_weights(query_vector, query_space, beta, gamma)\n",
    "        \n",
    "    try:\n",
    "        sim_matrix = (awesome_cossim_topn(query_vector, query_space.T,\n",
    "                                         ntop=n_neighbors, lower_bound=lower_bound))\n",
    "        \n",
    "        sim_matrix = sim_matrix.tocoo()\n",
    "    \n",
    "        idx = []\n",
    "        sim = []\n",
    "        arr_sizes = []\n",
    "        for row in range(sim_matrix.shape[0]):\n",
    "            s = sim_matrix.data[sim_matrix.row == row]\n",
    "            i = sim_matrix.col[sim_matrix.row == row]\n",
    "            sim.append(s)\n",
    "            idx.append(i)\n",
    "            arr_sizes.append(len(s))\n",
    "\n",
    "        max_size = max(arr_sizes)\n",
    "        idx = np.array([pad_to_shape(i, max_size) for i in idx]).astype(int)\n",
    "        sim = np.array([pad_to_shape(s, max_size) for i in sim])\n",
    "        if idx.shape[1] == 0:\n",
    "            raise ValueError('No similarity greater than lower_bound found. Choose a lower threshold.')\n",
    "        return  idx, sim\n",
    "    \n",
    "    except NameError: #in case sparse_dot_topn is not instaled\n",
    "        dist, idx = (\n",
    "            NearestNeighbors(n_neighbors = n_neighbors, radius = 1 - lower_bound, metric = 'cosine', n_jobs = -1)\n",
    "            .fit(query_space)\n",
    "            .kneighbors(query_vector)\n",
    "        )\n",
    "        return idx, 1 - dist # <- cos_sim = 1 - cos_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helping Classes - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DelegateEstimatorMixIn(object):\n",
    "    '''\n",
    "    class to make getattr method look for method in estimator object if not found in parent class.\n",
    "    parent class should contain 'estimator' attribute\n",
    "    '''\n",
    "    estimator = None\n",
    "    def __getattr__(self,attr):\n",
    "        # if use try except, gets infinite recursion\n",
    "        \n",
    "        if (attr in dir(self)) or (attr in list(self.__dict__)):\n",
    "            return object.__getattribute__(self, attr)\n",
    "        elif (attr in dir(self.estimator)) or (attr in list(self.estimator.__dict__)) and (not self.estimator):\n",
    "            return object.__getattribute__(self.estimator, attr)\n",
    "\n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_ensemble.ipynb.\n",
      "Converted 02_core.random_variable.ipynb.\n",
      "Converted 03_utils.ipynb.\n",
      "Converted 04_metrics.ipynb.\n",
      "Converted 05_neighbors.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
